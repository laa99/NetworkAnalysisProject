{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "The first two are for loading and storing dictionaries to/from a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_dict_pickle(file_name, dictionary):\n",
    "    \"\"\"\n",
    "        Saves a dictionary to a pickle file\n",
    "\n",
    "        :param file_name: the name of the file the data will be stored in\n",
    "        :type file_name: str\n",
    "\n",
    "        :param dictionary: the dictionary to be stored in the file\n",
    "        :type dictionary: dict\n",
    "    \"\"\"\n",
    "\n",
    "    with open('data/' + file_name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(dictionary, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_dict_pickle(file_name):\n",
    "    \"\"\"\n",
    "    Retrieves a dictionary form the specified file\n",
    "\n",
    "    :param file_name: the name of the file to load\n",
    "    :type file_name: str\n",
    "\n",
    "    :return: the dictionary retrieved from the file\n",
    "    :rtype dict\n",
    "    \"\"\"\n",
    "\n",
    "    with open('data/' + file_name + '.pkl', 'rb') as f:\n",
    "        dictionary =  pickle.load(f)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Artist-Country Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#intializing dictionary variables\n",
    "dict_05 = load_dict_pickle(\"2005_country_artist\")\n",
    "dict_06 = load_dict_pickle(\"2006_country_artist\")\n",
    "dict_07 = load_dict_pickle(\"2007_country_artist\")\n",
    "dict_08 = load_dict_pickle(\"2008_country_artist\")\n",
    "dict_09 = load_dict_pickle(\"2009_country_artist\")\n",
    "dict_10 = load_dict_pickle(\"2010_country_artist\")\n",
    "dict_13 = load_dict_pickle(\"2013_country_artist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Graphs From Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def top_artists(year_dict, top_number):\n",
    "    # create graph to represent trends for given year\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # loop through each artist in the dictionary\n",
    "    for country in year_dict:\n",
    "        # create country node & add it\n",
    "        G.add_node(country)\n",
    "        G.node[country]['country'] = True\n",
    "        \n",
    "        # get top 5 artists for current country\n",
    "        artists = copy.copy(year_dict[country])\n",
    "        num_artist = len(artists)\n",
    "        for i in range(top_number):\n",
    "            # make sure the country has enough top artists\n",
    "            if( num_artist < top_number):\n",
    "                # remove country's node and skip it\n",
    "                G.remove_node(country)\n",
    "                break;\n",
    "            \n",
    "            # find ith top artist\n",
    "            top = max(artists.keys(), key=(lambda k: artists[k]))\n",
    "            \n",
    "            #create node for ith top artist and make a conenction b/n it and the country\n",
    "            G.add_node(top)\n",
    "            G.node[top]['artist'] = True\n",
    "            G.add_edge(country, top, weight=year_dict[country][top])\n",
    "            \n",
    "            artists.pop(top)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pos = nx.spring_layout(G)\n",
    "# nx.draw(G, pos=pos);\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "G_05 = top_artists(dict_05, 5)\n",
    "G_06 = top_artists(dict_06, 5)\n",
    "G_07 = top_artists(dict_07, 5)\n",
    "G_08 = top_artists(dict_08, 5)\n",
    "G_09 = top_artists(dict_09, 5)\n",
    "\n",
    "# Takes two lists and calculates the JS Index associated with them.\n",
    "# Returns JS Index as a float\n",
    "def Jaccard(neighborhood1, neighborhood2):\n",
    "    \"\"\"\n",
    "        J(A,B) = |A n B| / |A U B| \n",
    "        A n B = elements in A AND B \n",
    "        A U B = elments in A OR B\n",
    "    \"\"\"\n",
    "    #want to iterate through longer list;\n",
    "    if len(neighborhood1) >= len(neighborhood2):\n",
    "        list1 = neighborhood1\n",
    "        list2 = neighborhood2\n",
    "    else:\n",
    "        list1 = neighborhood2\n",
    "        list2 = neighborhood1\n",
    "    \n",
    "    #AND --> A n B\n",
    "    intersection = 0\n",
    "    #OR --> A U B\n",
    "    #combined the lists & then get the set to only have unique occurrences. Then get the length\n",
    "    union = len(set(list1 + list2))\n",
    "    \n",
    "    #find the number of concordant and discordant nodes\n",
    "    for node in list1:\n",
    "        #if it's concordant\n",
    "        if node in list2:\n",
    "            intersection += 1\n",
    "\n",
    "    #calculate index\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1111111111111111, 0.1111111111111111, 0.25, 0.25]\n"
     ]
    }
   ],
   "source": [
    "index = Jaccard(G_08.neighbors('United States'), G_09.neighbors('United States'))\n",
    "\n",
    "# put the years in a dictionary\n",
    "graph_years = {5: G_05, 6: G_06, 7: G_07, 8: G_08, 9: G_09}\n",
    "years = [G_05, G_06, G_07, G_08, G_09]\n",
    "\n",
    "def years_similarity(years):\n",
    "    # getting Jaccard similarity for each country from years 2005-2006. Where the similarity is calculated for consecutive years\n",
    "    \n",
    "    # make dicionary to hold all similariteis\n",
    "    # dict['country'] = [05-06, 06-07, 07-08, 08-09] if value is not available, then it equals -1\n",
    "    results = dict()\n",
    "    \n",
    "    # get all countries from the graph\n",
    "    for graph in years:\n",
    "        x=1\n",
    "        for country in nx.get_node_attributes(graph, 'country').keys():\n",
    "            if not country in results:\n",
    "                results[country] = list()\n",
    "                \n",
    "    # get Jaccard Similarities\n",
    "    for i in range(len(years) - 1):\n",
    "        # get the jaccard similarity for the current year and next year countries\n",
    "        for country in results:\n",
    "            current_year = years[i] \n",
    "            next_year = years[i+1]\n",
    "            if country in current_year and country in next_year:\n",
    "                index = Jaccard(current_year.neighbors(country), next_year.neighbors(country))\n",
    "                results[country].append(index)\n",
    "            else:\n",
    "                results[country].append(-1)\n",
    "                    \n",
    "    return results\n",
    "\n",
    "x = years_similarity(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put Jaccard Similarities into CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_Jaccard_to_CSV(similarities):\n",
    "    file = open('data/jaccard_indexes.csv', 'w', newline='')\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # make header row\n",
    "    row = []\n",
    "    row.append('Country')\n",
    "    row.append('2005-2006')\n",
    "    row.append('2006-2007')\n",
    "    row.append('2007-2008')\n",
    "    row.append('2008-2009')\n",
    "\n",
    "    writer.writerow(row)\n",
    "\n",
    "    # write all the results from getting the Jaccard Similarities for\n",
    "    # all the countries\n",
    "    for country in similarities:\n",
    "        row = []\n",
    "        row.append(country)\n",
    "        for item in similarities[country]:\n",
    "            row.append(item)\n",
    "        writer.writerow(row)\n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "write_Jaccard_to_CSV(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
